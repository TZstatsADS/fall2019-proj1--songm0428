gd.sparse$k
head(gd.sparse$x)
gd <- grad.descent(huber.loss, beta, max.iter=200, step.size=0.001, stopping.deriv=0.1)
gd <- grad.descent(huber.loss, y, max.iter=200, step.size=0.001, stopping.deriv=0.1)
head(gd$x)
gd$k
gd <- grad.descent(huber.loss, beta, max.iter=200, step.size=0.001, stopping.deriv=0.1)
head(gd$x)
d <- grad.descent(huber.loss, beta, max.iter=200, step.size=0.001, stopping.deriv=0.1)
gd$x
gd <- grad.descent(huber.loss, beta, max.iter=200, step.size=0.001, stopping.deriv=0.1)
gd$x
library(numDeriv)
grad.descent <- function(
f, x0, max.iter = 200, step.size = 0.05, stopping.deriv = 0.01, ...) {
n    <- length(x0)
xmat <- matrix(0, nrow = n, ncol = max.iter)
xmat[,1] <- x0
for (k in 2:max.iter) {
# Calculate the gradient
grad.cur <- grad(f, xmat[ ,k-1], ...)
# Should we stop?
if (all(abs(grad.cur) < stopping.deriv)) {
k <- k-1; break
}
# Move in the opposite direction of the grad
xmat[ ,k] <- xmat[ ,k-1] - step.size * grad.cur
}
xmat <- xmat[ ,1:k] # Trim
return(list(x = xmat[,k], xmat = xmat, k = k))
}
p <- 10
beta <- rep(0,p)
gd <- grad.descent(huber.loss, beta, max.iter=200, step.size=0.001, stopping.deriv=0.1)
gd$x
gd <- grad.descent(huber.loss, beta, max.iter=200, step.size=0.001, stopping.deriv=0.1)
gd$x
obj <- apply(gd$xmat[, 1:gd$k], 2, huber.loss)
plot(1:gd$k, obj, xlab = "Iteration Number", ylab = "Objective Function Value", type = "l")
gd2 <- grad.descent(huber.loss, x0 = rep(0,p), max.iter=200, step.size=0.1, stopping.deriv=0.1)
gd2$x
plot((gd2$k-49):gd2$k, obj[(gd2$k- 49):gd2$k],
xlab = "Iteration Number", ylab = "Objective Function at each iteration")
plot((gd2$k-49):gd2$k, obj[(gd2$k- 49):gd2$k], type = "l"
xlab = "Iteration Number", ylab = "Objective Function at each iteration")
plot((gd2$k-49):gd2$k, obj[(gd2$k- 49):gd2$k], type = "l",
xlab = "Iteration Number", ylab = "Objective Function at each iteration")
plot((gd2$k-49):gd2$k, obj[(gd2$k- 49):gd2$k], type = "o",
xlab = "Iteration Number", ylab = "Objective Function at each iteration")
gd.sparse <- sparse.grad.descent(huber.loss, x0 = rep(0,p), max.iter=200, step.size=0.001, stopping.deriv=0.1)
gd.sparse$k
gd.sparse$x
gd <- grad.descent(huber.loss, y, max.iter=200, step.size=0.001, stopping.deriv=0.1)
head(gd$x)
gd$k
gd.sparse <- sparse.grad.descent(huber.loss, y, max.iter=200, step.size=0.001, stopping.deriv=0.1)
head(gd.sparse$x)
gd.sparse$k
gd <- grad.descent(huber.loss, y, max.iter=200, step.size=0.001, stopping.deriv=0.1)
head(gd$x)
gd$k
mse.loss <- function(beta) {
mean((b - beta)^2)
}
mse.loss(lm0$coef)
lm.coefs
lm0 <- lm(y~x)
lm0
y <- x %*% b + rt(n, df=2)
lm0 <- lm(y~x)
mse.loss <- function(beta) {
mean((b - beta)^2)
}
mse.loss(lm0$coef)
coefficients(lm0)
mse.loss(coefficients(lm0))
y <- x %*% b + rt(n, df=2)
pred <- matrix(rnorm(n*p), n, p)
beta <- c(1, 4)
resp <- pred %*% beta + rnorm(n)
lm.coefs <- coef(lm(resp ~ pred + 0))
lm.coefs <- coef(lm(y ~ x + 0))
lm.coefs
MSE <- function(beta) {
return(sum((y - x %*% b)^2))
}
grad.descent(MSE, x0 = c(0,0), step.size = 0.05,max.iter = 200)
out = grad.descent(MSE, x0 = c(0,0), step.size = 1e-3,max.iter = 200)
out$k
out$x
lm.coefs <- coef(lm(y ~ x))
grad.descent(MSE, y, step.size = 0.05,max.iter = 200)
x <- matrix(rnorm(n*p), n, p)
y <- rep(x,10)
y
y <- rep(x,1:10)
x <- matrix(rnorm(n*p), n, p)
head(x)
x <- matrix(rnorm(n*p), n, p)
head(x)
y1 <- x %*% b + rt(n, df=2)
for (i in 10){
y[i] <- x[i] %*% b + rt(n, df=2)
}
y[i] <- x %*% b + rt(n, df=2)
for (i in 10){
y[i] <- x %*% b + rt(n, df=2)
}
for (i in 10){
y[i] <- x %*% b + rt(n, df=2)
}
y <- rep(x %*% b + rt(n, df=2),10)
y
gd <- grad.descent(huber.loss, y, max.iter=200, step.size=0.001, stopping.deriv=0.1)
head(gd$x)
y <- x %*% b + rt(n, df=2)
lm.coefs <- coef(lm(y ~ x))
lm.coefs
n <- 100
p <- 10
s <- 3
set.seed(0)
x <- matrix(rnorm(n*p), n, p)
b <- c(-0.7, 0.7, 1, rep(0, p-s))
y <- x %*% b + rt(n, df=2)
lm.coefs <- coef(lm(y ~ x))
lm.coefs
mydata <- read.csv(choose.file())
mydata <- read.csv(file.choose()
```
mydata <- read.csv(file.choose())
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
head(mydata)
ggplot(data = mydata, aes(x=carat,y=price))+
geom_point()
ggplot(data = mydata, aes(x=carat,y=price), colour=clarity)+
geom_point()
ggplot(data = mydata, aes(x=carat,y=price), colours=clarity)+
geom_point()
library("colorspace", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
ggplot(data = mydata, aes(x=carat,y=price), colour=clarity)+
geom_point()
detach("package:colorspace", unload=TRUE)
library(RColorBrewer)
ggplot(data = mydata, aes(x=carat,y=price), colour=clarity)+
geom_point()
knitr::opts_chunk$set(echo = TRUE)
myColors <- brewer.pal(5,"Set1")
names(myColors) <- levels(dat$grp)
dat <- data.frame(x=runif(10),y=runif(10),
grp = rep(LETTERS[1:5],each = 2),stringsAsFactors = TRUE)
myColors <- brewer.pal(5,"Set1")
names(myColors) <- levels(dat$grp)
colScale <- scale_colour_manual(name = "grp",values = myColors)
ggplot(data = mydata, aes(x=carat,y=price), colour=clarity)+
geom_point()
ggplot(data = mydata, aes(x=carat,y=price), colour=clarity)+
geom_point()
ggplot(data = mydata, aes(x=carat,y=price), colour="red")+
geom_point()
ggplot(data = mydata, aes(x=carat,y=price), colour=clarity)+
geom_point(alpha=0.1)
ggplot(data = mydata[mydata$carat<2.5,], aes(x=carat,y=price), colour=clarity)+
geom_point(alpha=0.1)
ggplot(data = mydata[mydata$carat<2.5,], aes(x=carat,y=price), colour=clarity)+
geom_point(alpha=0.1) +
geom_smooth()
x <- c(5, 29, 13, 87)
x
x <- 1:50
x
x <- 2
mode(x)
typeof(x)
y <- as.integer(3)
typeof(y)
z <- 1 - 2i
z
typeof(z)
name <- "Columbia University"
name
typeof(name)
a <- TRUE
b <- F
a
b
typeof(a)
3*TRUE # Logicals in arithmetic
mode(3*TRUE)
mode("147")
x <- c(2, pi, 1/2, 3^2)
x
y <- c("NYC", "Boston", "Philadelphia")
y
z <- 5:10
z
u <- rep(1, 18)
u
v <- c() # empty vector and fill in each part
v[1] <- TRUE # first element of v
v[2] <- TRUE
v[3] <- FALSE
v
vec1 <- rep(-27, 3)
vec1
vec2 <- c(vec1, c(-26, -25, -24))
vec2
mat <- matrix(1:9, nrow = 3, ncol = 3)
mat
new_mat <- matrix(1:9, nrow = 3, ncol = 3, byrow = TRUE)
new_mat
this_mat <- matrix(nrow = 2, ncol = 2)
this_mat[1,1] <- sqrt(27)
this_mat[1,2] <- round(sqrt(27), 3)
this_mat[2,1] <- exp(1)
this_mat[2,2] <- log(1)
this_mat
vec1 <- rep(0, 4)
vec2 <- c("We're", "making", "matrices", "!")
final_mat <- rbind(vec1, vec2)
final_mat
this_mat # Defined previously
colnames(this_mat) # Nothing there yet
colnames(this_mat) <- c("Column1", "Column2")
this_mat
vec <- c(1.75, TRUE, "abc")
vec
str(vec)
y <- c(27, -34, 19, 7, 61)
y[2]
y[3:5]
y[c(1, 4)]
y <- c(27, -34, 19, 7, 61)
y
y[c(1, 4)] <- 0
y
y <- c(27, -34, 19, 7, 61)
y
y[-c(1, 4)] # remove num1 and num4, y is not changed
y
y <- y[-1] # remove num1 and changed y
y
mat <- matrix(1:8, ncol = 4)
mat
mat[, 2:3] # extract column2 and 3
this_mat
this_mat[, "Column2"] # extract column2 as vector
this_mat[, -1] # remove column1
install.packages("pixmap")
library(tm)
library(readr)
library(tau)
library(openNLP)
library(Matrix)
library(stringi)
install.packages('openNLP')
# Install necessary libraries
install.packages('tm')
library(tm)
# Install necessary libraries
install.packages('tm')
library(tm)
intall.packages("slam")
install.packages("slam")
install.packages("slam")
source("http://bioconductor.org/biocLite.R")
biocLite("devtools")    # only if devtools not yet installed
library('sleuth')
install.packages("sleuth")
lyrics_list <- c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock", "Metal", "Pop", "Hip-Hop", "Other")
time_list <- c("1970s", "1980s", "1990s", "2000s", "2010s")
corpus <- VCorpus(VectorSource(dt_lyrics$stemmedwords))
word_tibble <- tidy(corpus) %>%
select(text) %>%
mutate(id = row_number()) %>%
unnest_tokens(word, text)
# Chunk 1: load libraries
library(tidyverse)
library(tidytext)
library(plotly)
library(DT)
library(tm)
library(data.table)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
# Chunk 2: load data
# load lyrics data
load('../output/processed_lyrics.RData')
# load artist information
dt_artist <- fread('../data/artists.csv')
# Chunk 3
lyrics_list <- c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock", "Metal", "Pop", "Hip-Hop", "Other")
time_list <- c("1970s", "1980s", "1990s", "2000s", "2010s")
corpus <- VCorpus(VectorSource(dt_lyrics$stemmedwords))
word_tibble <- tidy(corpus) %>%
select(text) %>%
mutate(id = row_number()) %>%
unnest_tokens(word, text)
# Chunk 4
# Define UI for app that draws a histogram ----
ui <- navbarPage(strong("Lyrics Analysis"),
tabPanel("Overview",
titlePanel("Most frequent words"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
sliderInput(inputId = "nwords1",
label = "Number of terms in the first word cloud:",
min = 5, max = 100, value = 50),
selectInput('genre1', 'Genre of the first word cloud',
lyrics_list, selected='Folk')
),
# Main panel for displaying outputs ----
mainPanel(
wordcloud2Output(outputId = "WC1", height = "300")
)
),
hr(),
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
sliderInput(inputId = "nwords2",
label = "Number of terms in the second word cloud:",
min = 5, max = 100, value = 50),
selectInput('genre2', 'Genre of the second word cloud',
lyrics_list, selected='Metal')
),
# Main panel for displaying outputs ----
mainPanel(
wordcloud2Output(outputId = "WC2", height = "300")
)
)
),
tabPanel("Time Variation",
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
selectInput('decade1', 'Selected decade for the first plot:',
time_list, selected='1970s'),
selectInput('decade2', 'Selected decade for the second plot:',
time_list, selected='1980s'),
numericInput(inputId = "topBigrams",
label = "Number of top pairs to view:",
min = 1,
max = 20,
value = 10)
),
# Main panel for displaying outputs ----
mainPanel(
fluidRow(
column(5,
plotlyOutput("bigram1")),
column(5,
plotlyOutput("bigram2"))
)
)
)
),
tabPanel("Data",
DT::dataTableOutput("table"))
)
# Chunk 5
server <- function(input, output) {
output$WC1 <- renderWordcloud2({
count(filter(word_tibble, id %in% which(dt_lyrics$genre == input$genre1)), word, sort = TRUE) %>%
slice(1:input$nwords1) %>%
wordcloud2(size=0.6, rotateRatio=0.2)
})
output$WC2 <- renderWordcloud2({
count(filter(word_tibble, id %in% which(dt_lyrics$genre == input$genre2)), word, sort = TRUE) %>%
slice(1:input$nwords2) %>%
wordcloud2(size=0.6, rotateRatio=0.2)
})
output$bigram1 <- renderPlotly({
year_start <- as.integer(substr(input$decade1, 1, 4))
dt_sub <- filter(dt_lyrics, year>=year_start) %>%
filter(year<(year_start+10))
lyric_bigrams <- dt_sub %>%
unnest_tokens(bigram, stemmedwords, token = "ngrams", n = 2)
bigram_counts <- lyric_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
combined_words <- apply(bigram_counts[c(1, 2)], 1, paste , collapse = " " )[1:input$topBigrams]
x_names <- factor(combined_words, levels = rev(combined_words))
plot_ly(
x = bigram_counts$n[1:input$topBigrams],
y = x_names,
name = "Bigram",
type = "bar",
orientation = 'h'
)
})
output$bigram2 <- renderPlotly({
year_start <- as.integer(substr(input$decade2, 1, 4))
dt_sub <- filter(dt_lyrics, year>=year_start) %>%
filter(year<(year_start+10))
lyric_bigrams <- dt_sub %>%
unnest_tokens(bigram, stemmedwords, token = "ngrams", n = 2)
bigram_counts <- lyric_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
combined_words <- apply(bigram_counts[c(1, 2)], 1, paste , collapse = " " )[1:input$topBigrams]
x_names <- factor(combined_words, levels = rev(combined_words))
plot_ly(
x = bigram_counts$n[1:input$topBigrams],
y = x_names,
name = "Bigram",
type = "bar",
orientation = 'h'
)
})
output$table <- DT::renderDataTable({
DT::datatable(dt_lyrics)
})
}
# Chunk 6: shiny app
shinyApp(ui, server)
library(tidyverse)
library(tidytext)
library(plotly)
library(DT)
library(tm)
library(data.table)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
lyrics_list <- c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock", "Metal", "Pop", "Hip-Hop", "Other")
time_list <- c("1970s", "1980s", "1990s", "2000s", "2010s")
corpus <- VCorpus(VectorSource(dt_lyrics$stemmedwords))
word_tibble <- tidy(corpus) %>%
select(text) %>%
mutate(id = row_number()) %>%
unnest_tokens(word, text)
lyrics_list <- c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock", "Metal", "Pop", "Hip-Hop", "Other")
time_list <- c("1970s", "1980s", "1990s", "2000s", "2010s")
corpus <- VCorpus(VectorSource(dt_lyrics$stemmedwords))
word_tibble <- tidy(corpus) %>%
select(text) %>%
mutate(id = row_number()) %>%
unnest_tokens(word, text)
library(tm)
library(data.table)
library(tidytext)
library(tidyverse)
library(DT)
library(plotly)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
### Load the processed lyrics data along with artist information
# We use the processed data and artist information for our analysis.
# load lyrics data and processed_lyrics
load('/Users/mingming/Desktop/Fall 2019/ADS/fall2019-proj1--songm0428/output/processed_lyrics.RData')
load("/Users/mingming/Desktop/Fall 2019/ADS/fall2019-proj1--songm0428/data/lyrics.RData")
# load artist information
dt_artist <- fread('/Users/mingming/Desktop/Fall 2019/ADS/fall2019-proj1--songm0428/data/artists.csv')
lyrics_list <- c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock", "Metal", "Pop", "Hip-Hop", "Other")
time_list <- c("1970s", "1980s", "1990s", "2000s", "2010s")
corpus <- VCorpus(VectorSource(dt_lyrics$stemmedwords))
word_tibble <- tidy(corpus) %>%
select(text) %>%
mutate(id = row_number()) %>%
unnest_tokens(word, text)
corp <- Corpus(VectorSource(dt_lyrics$stemmedwords))
load('../output/processed_lyrics.RData')
library(tm)
library(tidytext)
library(tidyverse)
library(tidyr)
library(dplyr)
library(slam)
library(LDAvis)
library(servr)
library(topicmodels)
library(gridExtra)
library(ggridges)
load('../output/processed_lyrics.RData')
load("../data/lyrics.RData")
corp <- Corpus(VectorSource(dt_lyrics$stemmedwords))
dtm <- DocumentTermMatrix(corp)
#  filter(dt_lyrics_re %in% c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock",
# "Metal", "Pop", "Hip-Hop", "Other"))
setwd("~/Desktop/Fall 2019/ADS/fall2019-proj1--songm0428/doc")
library(tm)
library(tidytext)
library(tidyverse)
library(tidyr)
library(dplyr)
library(slam)
library(LDAvis)
library(servr)
library(topicmodels)
library(gridExtra)
library(ggridges)
load('../output/processed_lyrics.RData')
load("../data/lyrics.RData")
corp <- Corpus(VectorSource(dt_lyrics$stemmedwords))
dtm <- DocumentTermMatrix(corp)
#  filter(dt_lyrics_re %in% c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock",
# "Metal", "Pop", "Hip-Hop", "Other"))
corp <- Corpus(VectorSource(dt_lyrics$stemmedwords))
dtm <- DocumentTermMatrix(corp)
View(dt_lyrics)
